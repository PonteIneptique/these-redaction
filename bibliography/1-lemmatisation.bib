@inproceedings{schofield2017quantifying,
  title={Quantifying the Effects of Text Duplication on Semantic Models},
  author={Schofield, Alexandra and Thompson, Laure and Mimno, David},
  booktitle={Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing},
  pages={2727--2737},
  year={2017}
}


@article{SyntaxNetConll2017,
  author    = {Chris Alberti and
               Daniel Andor and
               Ivan Bogatyy and
               Michael Collins and
               Dan Gillick and
               Lingpeng Kong and
               Terry Koo and
               Ji Ma and
               Mark Omernick and
               Slav Petrov and
               Chayut Thanapirom and
               Zora Tung and
               David Weiss},
  title     = {SyntaxNet Models for the CoNLL 2017 Shared Task},
  journal   = {CoRR},
  volume    = {abs/1703.04929},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.04929},
  archivePrefix = {arXiv},
  eprint    = {1703.04929},
  timestamp = {Sun, 12 Nov 2017 23:10:48 +0100},
  biburl    = {http://dblp.org/rec/bib/journals/corr/AlbertiABCGKKMO17},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{mellet2002atouts,
  title={Les atouts multiples de la lemmatisation: l’exemple du latin},
  author={Mellet, Sylvie and Purnelle, G{\'e}rald},
  journal={JADT 2002, 6es Journ{\'e}es internationales d’Analyse statistique des Donn{\'e}es Textuelles},
  pages={529--538},
  year={2002}
}

@article{BodsonCodification1966,
	title = {Codification d'un texte latin sur cartes mécanographiques {IBM} 80 colonnes},
	volume = {1966},
	url = {http://web.philo.ulg.ac.be/rissh/wp-content/uploads/sites/10/pdf/Annee1966/01/ABodson.pdf},
	year = {1966},
	pages = {1--46},
	number = {1},
	journal = {Revue Informatique et Statistique dans les Sciences humaines},
	author = {Bodson, Arthur and Govaerts, Suzanne},
	date = {1966}
}

@article{poudat2009variations,
  title={Variations langagi{\`e}res et annotation morphosyntaxique du latin classique},
  author={Poudat, C{\'e}line and Longr{\'e}e, Doninique},
  journal={Traitement Automatique des Langues},
  volume={50},
  number={2},
  pages={129--148},
  year={2009}
}
@article{schmid1994treetagger,
  title={TreeTagger-a language independent part-of-speech tagger},
  author={Schmid, Helmut},
  journal={http://www. ims. uni-stuttgart. de/projekte/corplex/TreeTagger/},
  year={1994}
}

@article{schachter1985parts,
  title={Parts-of-speech systems},
  author={Schachter, Paul and Shopen, Timothy},
  journal={Language typology and syntactic description},
  volume={1},
  pages={3--61},
  year={1985}
}

@article {Cafieroeaax5489,
	author = {Cafiero, Florian and Camps, Jean-Baptiste},
	title = {Why Moli{\`e}re most likely did write his plays},
	volume = {5},
	number = {11},
	elocation-id = {eaax5489},
	year = {2019},
	doi = {10.1126/sciadv.aax5489},
	publisher = {American Association for the Advancement of Science},
	abstract = {As for Shakespeare, a hard-fought debate has emerged about Moli{\`e}re, a supposedly uneducated actor who, according to some, could not have written the masterpieces attributed to him. In the past decades, the century-old thesis according to which Pierre Corneille would be their actual author has become popular, mostly because of new works in computational linguistics. These results are reassessed here through state-of-the-art attribution methods. We study a corpus of comedies in verse by major authors of Moli{\`e}re and Corneille{\textquoteright}s time. Analysis of lexicon, rhymes, word forms, affixes, morphosyntactic sequences, and function words do not give any clue that another author among the major playwrights of the time would have written the plays signed under the name Moli{\`e}re.},
	URL = {https://advances.sciencemag.org/content/5/11/eaax5489},
	eprint = {https://advances.sciencemag.org/content/5/11/eaax5489.full.pdf},
	journal = {Science Advances}
}

@inproceedings{feldman2009part,
  title={Part-of-speech histograms for genre classification of text},
  author={Feldman, Sergey and Marin, Marius A and Ostendorf, Mari and Gupta, Maya R},
  booktitle={2009 IEEE International Conference on Acoustics, Speech and Signal Processing},
  pages={4781--4784},
  year={2009},
  organization={IEEE}
}
@article{wang2015pos,
  title={POS-RS: A Random Subspace method for sentiment classification based on part-of-speech analysis},
  author={Wang, Gang and Zhang, Zhu and Sun, Jianshan and Yang, Shanlin and Larson, Catherine A},
  journal={Information Processing \& Management},
  volume={51},
  number={4},
  pages={458--479},
  year={2015},
  publisher={Elsevier}
}

@article{zirikly2014named,
  title={Named entity recognition for dialectal arabic},
  author={Zirikly, Ayah and Diab, Mona},
  journal={ANLP 2014},
  volume={78},
  year={2014},
  publisher={Citeseer}
}

@unpublished{perreaux_lemmatisation_2019,
	location = {Paris, France},
	title = {La lemmatisation des corpus médiévaux: pourquoi et comment \?},
	type = {Journée d'étude},
	howpublished = {Journée d'étude},
	note = {Initiation à la lemmatisation des textes médiévaux, Cosme2},
	author = {Perreaux, Nicolas},
	date = {2019-06-17},
	year={2019}
}

@incollection{rouse_concordance_1984,
	title = {La concordance verbale des Ecritures},
	volume = {4},
	isbn = {2-7010-1091-8},
	series = {Bible de tous les temps},
	pages = {115--122},
	booktitle = {Le Moyen-Âge et la Bible},
	publisher = {Beauchesne},
	author = {Rouse, Mary A. and Rouse, Richard H.},
	year = {1984}
}

@article{delatte_laboratoire_1961,
	title = {Un laboratoire d'analyse statistique des langues anciennes à l'{Université} de {Liège}},
	volume = {30},
	doi = {10.3406/antiq.1961.3417},
	journal = {L'Antiquité Classique},
	author = {Delatte, Louis and {\'E}vrard, {\'E}tienne},
	year = {1961},
	pages = {429--444}
}

@article{delatte_propos_1965,
	title = {A propos d'une concordance},
	volume = {34},
	copyright = {free},
	doi = {10.3406/antiq.1965.1456},
	language = {fre},
	number = {2},
	urldate = {2020-04-01},
	journal = {L'Antiquité Classique},
	author = {Delatte, Louis},
	year = {1965},
	note = {Company: Persée - Portail des revues scientifiques en SHS
Distributor: Persée - Portail des revues scientifiques en SHS
Institution: Persée - Portail des revues scientifiques en SHS
Label: Persée - Portail des revues scientifiques en SHS
Publisher: L'Antiquité Classique},
	pages = {534--541},
}

@article{delatte_index_1968,
	title = {Index ou concordance ?},
	volume = {37},
	copyright = {free},
	doi = {10.3406/antiq.1968.1505},
	language = {fre},
	number = {1},
	urldate = {2020-04-01},
	journal = {L'Antiquité Classique},
	author = {Delatte, Louis},
	year = {1968},
	pages = {192--204}
}

@article{grimal_index_1966,
	title = {Index et concordances},
	volume = {44},
	journal = {Revue d'Études Latines},
	author = {Grimal, Pierre},
	year = {1966},
	pages = {534--541},
}

@article{grimal_delatte_1964,
	title = {Delatte ({L}.) et {Evrard} ({E}.). {Sénèque}. {Consolation} à {Polybe}. {Index} {Verborum}. {Relevés} statistiques},
	volume = {42},
	copyright = {free},
	language = {fre},
	number = {1},
	urldate = {2020-04-02},
	journal = {Revue belge de Philologie et d'Histoire},
	author = {Grimal, Pierre},
	year = {1964},
	pages = {130--133},
}


@article{verdiere_pierre_1970,
	title = {Pierre {Grimal}, {L}. {Annaei} {Senecae} operum moralium concordantia, {IV}. {De} prouidentia ; ; {Pierre} {Grimal}, {L}. {Annaei} {Senecae} operum moralium concordantia, {V}. {De} uita beata},
	volume = {39},
	copyright = {free},
	language = {fre},
	number = {2},
	urldate = {2020-04-03},
	journal = {L'Antiquité Classique},
	author = {Verdière, Raoul},
	year = {1970},
}


@article{delatte_concordantiae_1979,
	title = {Concordantiae {Senecae}. {Quid} ?},
	number = {1},
	journal = {Revue LASLA},
	author = {Delatte, Louis and Govaerts, Suzanne and Denooz, J.},
	year = {1979},
	pages = {25--32}
}


@article{crane_generating_1991,
	title = {Generating and {Parsing} {Classical} {Greek}},
	volume = {6},
	issn = {0268-1145, 1477-4615},
	url = {https://academic.oup.com/dsh/article-lookup/doi/10.1093/llc/6.4.243},
	doi = {10.1093/llc/6.4.243},
	language = {en},
	number = {4},
	urldate = {2020-04-06},
	journal = {Literary and Linguistic Computing},
	author = {Crane, G.},
	month = oct,
	year = {1991},
	pages = {243--245}
}

@misc{ouvrard_collatinus_1999,
	title = {Collatinus},
	url = {collatinus.org},
	author = {Ouvrard, Yves},
	year = {1999}
}

@misc{ouvrard_analysis_1992,
	title = {Analysis},
	url = {collatinus.org},
	author = {Ouvrard, Yves},
	year = {1992}
}

@misc{bozzi_lemlat_1992,
	title = {{LEMLAT}},
	url = {http://www.lemlat3.eu/about/credits/},
	publisher = {CNR-ILC},
	author = {Bozzi, Andrea and Cappelli, Giuseppe and Marinone, Nino},
	year = {1992}
}

@misc{whitaker_words_1993,
	title = {Words},
	url = {http://archives.nd.edu/whitaker/wordsdoc.htm},
	author = {Whitaker, William},
	year = {1993}
}

@article{delatte_programme_1965,
	title = {Programme d'analyse morphologique et syntaxique du latin},
	volume = {1},
	journal = {Revue LASLA},
	author = {Delatte, Louis},
	year = {1965},
	pages = {57--62}
}


@misc{mambrini_harmonizing_2019,
	title = {Harmonizing {Different} {Lemmatization} {Strategies} for {Building} a {Knowledge} {Base} of {Linguistic} {Resources} for {Latin}},
	url = {https://zenodo.org/record/3349631\#.XosiTPFS9hE},
	language = {eng},
	urldate = {2020-04-06},
	author = {Mambrini, Francesco and Passarotti, Marco Carlo},
	month = jul,
	year = {2019},
	doi = {10.5281/zenodo.3349631}
}

@Misc{johnson2014cltk,
    author = {Kyle P. Johnson et al.},
    title = {CLTK: The Classical Language Toolkit},
    howpublished = {\url{https://github.com/cltk/cltk}},
    note = {{DOI} 10.5281/zenodo.593336},
    year = {2014},
}


@inproceedings{eger_lexicon-assisted_2015,
	title = {Lexicon-assisted tagging and lemmatization in {Latin}: {A} comparison of six taggers and two lemmatization methods},
	shorttitle = {Lexicon-assisted tagging and lemmatization in {Latin}},
	booktitle = {Proceedings of the 9th {SIGHUM} {Workshop} on {Language} {Technology} for {Cultural} {Heritage}, {Social} {Sciences}, and {Humanities} ({LaTeCH})},
	author = {Eger, Steffen and vor der Brück, Tim and Mehler, Alexander},
	year = {2015},
	pages = {105--113},
	file = {Full Text:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/KKPDHP7F/Eger et al. - 2015 - Lexicon-assisted tagging and lemmatization in Lati.pdf:application/pdf}
}

@article{brants_tnt_2000,
	title = {{TnT} - {A} {Statistical} {Part}-of-{Speech} {Tagger}},
	url = {https://arxiv.org/abs/cs/0003055v1},
	abstract = {Trigrams'n'Tags (TnT) is an efficient statistical part-of-speech tagger.
Contrary to claims found elsewhere in the literature, we argue that a tagger
based on Markov models performs at least as well as other current approaches,
including the Maximum Entropy framework. A recent comparison has even shown
that TnT performs significantly better for the tested corpora. We describe the
basic model of TnT, the techniques used for smoothing and for handling unknown
words. Furthermore, we present evaluations on two corpora.},
	language = {en},
	urldate = {2020-04-06},
	author = {Brants, Thorsten},
	month = mar,
	year = {2000},
	file = {Full Text PDF:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/KUEUIQU4/Brants - 2000 - TnT - A Statistical Part-of-Speech Tagger.pdf:application/pdf;Snapshot:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/EK7MJLNA/0003055.html:text/html}
}

@inproceedings{toutanova_feature-rich_2003,
	address = {Edmonton, Canada},
	series = {{NAACL} '03},
	title = {Feature-rich part-of-speech tagging with a cyclic dependency network},
	url = {https://doi.org/10.3115/1073445.1073478},
	doi = {10.3115/1073445.1073478},
	abstract = {We present a new part-of-speech tagger that demonstrates the following ideas: (i) explicit use of both preceding and following tag contexts via a dependency network representation, (ii) broad use of lexical features, including jointly conditioning on multiple consecutive words, (iii) effective use of priors in conditional loglinear models, and (iv) fine-grained modeling of unknown word features. Using these ideas together, the resulting tagger gives a 97.24\% accuracy on the Penn Treebank WSJ, an error reduction of 4.4\% on the best previous single automatically learned tagging result.},
	urldate = {2020-04-06},
	booktitle = {Proceedings of the 2003 {Conference} of the {North} {American} {Chapter} of the {Association} for {Computational} {Linguistics} on {Human} {Language} {Technology} - {Volume} 1},
	publisher = {Association for Computational Linguistics},
	author = {Toutanova, Kristina and Klein, Dan and Manning, Christopher D. and Singer, Yoram},
	month = may,
	year = {2003},
	pages = {173--180},
	file = {Full Text PDF:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/BI4H7VIA/Toutanova et al. - 2003 - Feature-rich part-of-speech tagging with a cyclic .pdf:application/pdf}
}


@misc{tanz_how_2017,
	title = {How video game tech makes neural networks possible},
	url = {https://social.techcrunch.com/2017/10/27/how-video-game-tech-makes-neural-networks-possible/},
	abstract = {Thanks to the creation of ever more powerful GPUs deep machine learning and neural networks are poised to change almost every aspect of society -- from the jobs we pursue and the cars we drive to the diagnosis we receive when we go to the doctor.},
	language = {en-US},
	urldate = {2020-04-07},
	journal = {TechCrunch},
	author = {Tanz, Ophir},
	year = {2017},
	note = {Library Catalog: techcrunch.com},
	file = {Snapshot:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/DVIUVQJL/how-video-game-tech-makes-neural-networks-possible.html:text/html}
}


@article{kestemont_lemmatization_2017,
	title = {Lemmatization for variation-rich languages using deep learning},
	volume = {32},
	issn = {2055-7671},
	url = {https://academic.oup.com/dsh/article/32/4/797/2669790},
	doi = {10.1093/llc/fqw034},
	abstract = {Abstract.  In this article, we describe a novel approach to sequence tagging for languages that are rich in (e.g. orthographic) surface variation. We focus on l},
	language = {en},
	number = {4},
	urldate = {2018-11-26},
	journal = {Digital Scholarship in the Humanities},
	author = {Kestemont, Mike and de Pauw, Guy and van Nie, Renske and Daelemans, Walter},
	month = dec,
	year = {2017},
	pages = {797--815},
	file = {Full Text PDF:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/UN9YAV38/Kestemont et al. - 2017 - Lemmatization for variation-rich languages using d.pdf:application/pdf;Snapshot:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/VD46SK6W/2669790.html:text/html}
}

@article{manjavacas_improving_2019,
	title = {Improving {Lemmatization} of {Non}-{Standard} {Languages} with {Joint} {Learning}},
	url = {http://arxiv.org/abs/1903.06939},
	abstract = {Lemmatization of standard languages is concerned with (i) abstracting over morphological differences and (ii) resolving token-lemma ambiguities of inflected words in order to map them to a dictionary headword. In the present paper we aim to improve lemmatization performance on a set of non-standard historical languages in which the difficulty is increased by an additional aspect (iii): spelling variation due to lacking orthographic standards. We approach lemmatization as a string-transduction task with an encoder-decoder architecture which we enrich with sentence context information using a hierarchical sentence encoder. We show significant improvements over the state-of-the-art when training the sentence encoder jointly for lemmatization and language modeling. Crucially, our architecture does not require POS or morphological annotations, which are not always available for historical corpora. Additionally, we also test the proposed model on a set of typologically diverse standard languages showing results on par or better than a model without enhanced sentence representations and previous state-of-the-art systems. Finally, to encourage future work on processing of non-standard varieties, we release the dataset of non-standard languages underlying the present study, based on openly accessible sources.},
	urldate = {2019-11-24},
	journal = {arXiv:1903.06939 [cs]},
	author = {Manjavacas, Enrique and Kádár, Ákos and Kestemont, Mike},
	month = mar,
	year = {2019},
	note = {arXiv: 1903.06939},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/4KGZXA5M/Manjavacas et al. - 2019 - Improving Lemmatization of Non-Standard Languages .pdf:application/pdf;arXiv.org Snapshot:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/UX5SWX33/1903.html:text/html}
}

@article{de_gussem_integrated_2017,
	title = {Integrated {Sequence} {Tagging} for {Medieval} {Latin} {Using} {Deep} {Representation} {Learning}},
	volume = {Special Issue on Computer-Aided Processing of Intertextuality in Ancient Languages},
	url = {https://jdmdh.episciences.org/3835/pdf},
	abstract = {In this paper we consider two sequence tagging tasks for medieval Latin: part-of-speech tagging and lemmatization. These are both basic, yet foundational preprocessing steps in applications such as text re-use detection. Nevertheless, they are generally complicated by the considerable orthographic variation which is typical of medieval Latin. In Digital Classics, these tasks are traditionally solved in a (i) cascaded and (ii) lexicon-dependent fashion. For example, a lexicon is used to generate all the potential lemma-tag pairs for a token, and next, a context-aware PoS-tagger is used to select the most appropriate tag-lemma pair. Apart from the problems with out-of-lexicon items, error percolation is a major downside of such approaches. In this paper we explore the possibility to elegantly solve these tasks using a single, integrated approach. For this, we make use of a layered neural network architecture from the field of deep representation learning.},
	language = {en},
	urldate = {2020-04-07},
	journal = {Journal of Data Mining \& Digital Humanities},
	author = {De Gussem, Jeroen and Kestemont, Mike},
	month = aug,
	year = {2017},
	note = {Publisher: Episciences.org},
	file = {Full Text PDF:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/6PXBELLT/De Gussem and Kestemont - 2017 - Integrated Sequence Tagging for Medieval Latin Usi.pdf:application/pdf;Snapshot:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/S9HU2WYA/view.html:text/html}
}


@article{citroni_les_2008,
	title = {Les proèmes des {Priapées} et le problème de la datation du recueil},
	volume = {38},
	copyright = {free},
	url = {https://www.persee.fr/doc/mom_0151-7015_2008_act_38_1_2492},
	abstract = {Un nouvel examen de l’argumentation apologétique développée dans les deux proèmes des Priapées, et en particulier une mise au point de la structure logique et de la signification du second proème, confirme, sur des bases différentes de celles adoptées par Buchheit, la thèse de Buchheit lui-même, selon lequel les deux proèmes des Priapées représentent deux moments d’un unique projet apologétique. La comparaison avec les motifs apologétiques des épigrammes de Martial permet de confirmer l’existence d’un rapport direct entre le premier proème des Priapées et la dédicace à Domitien du premier livre de Martial – rapport qui ne se fonde pas seulement sur le parallélisme bien connu entre le deuxième vers du proème des Priapées et le deuxième vers de Martial I 4, mais aussi sur une autre relation, pas encore observée jusqu’ici, entre le distique final de ce proème et le troisième distique de l’épigramme de Martial. Ces considérations conduisent à penser que le recueil des Priapées a été construit, et doté de ses proèmes, à une date postérieure à la publication du premier livre de Martial, vu la difficulté à prendre comme une allusion au commencement des Priapées le poème par lequel Martial dédie son premier livre à l’empereur comme censor perpetuus. La sélection des trois mètres qui seuls sont admis dans le recueil démontre le choix d’une typologie épigrammatique précise : cela aussi oriente vers une date postérieure à Martial, étant donné que cette typologie, qui est une caractéristique constante des livres I-XII de Martial, ne semble pas connue et, quoiqu’il en soit, n’était pas pratiquée parmi les auteurs d’épigrammes de l’entourage de Pline le Jeune.},
	language = {fre},
	number = {1},
	urldate = {2020-11-05},
	journal = {MOM Éditions},
	author = {Citroni, Mario},
	year = {2008},
	note = {Publisher: Persée - Portail des revues scientifiques en SHS},
	pages = {35--51},
	file = {Snapshot:/home/thibault/Zotero/storage/R465YRLH/mom_0151-7015_2008_act_38_1_2492.html:text/html}
}

@inproceedings{optuna_2019,
    title={Optuna: A Next-generation Hyperparameter Optimization Framework},
    author={Akiba, Takuya and Sano, Shotaro and Yanase, Toshihiko and Ohta, Takeru and Koyama, Masanori},
    booktitle={Proceedings of the 25rd {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
    year={2019}
}

@article{camacho-collados_role_2018,
	title = {On the {Role} of {Text} {Preprocessing} in {Neural} {Network} {Architectures}: {An} {Evaluation} {Study} on {Text} {Categorization} and {Sentiment} {Analysis}},
	shorttitle = {On the {Role} of {Text} {Preprocessing} in {Neural} {Network} {Architectures}},
	url = {http://arxiv.org/abs/1707.01780},
	urldate = {2020-11-18},
	journal = {arXiv:1707.01780 [cs]},
	author = {Camacho-Collados, Jose and Pilehvar, Mohammad Taher},
	month = aug,
	year = {2018},
	note = {arXiv: 1707.01780},
}


@incollection{fruyt_adverbes_2008,
	address = {Paris},
	edition = {L'Harmattan},
	series = {Série {Grammaire} et {Linguistique}, {Collection} {KUBABA}},
	title = {Adverbes latins, grammaticalisation et lexicalisation},
	number = {2},
	booktitle = {Adverbes et évolution linfuistique en latin},
	author = {Fruyt, Michèle},
	editor = {Fruyt, Michèle and Van Laer, Sophie},
	year = {2008},
	pages = {49--66}
}

@incollection{brunet_merito_2008,
	address = {Paris},
	edition = {L'Harmattan},
	series = {Série {Grammaire} et {Linguistique}, {Collection} {KUBABA}},
	title = {Merito et iniuria: deux cas d'adverbialisation du substantif},
	number = {2},
	booktitle = {Adverbes et évolution linfuistique en latin},
	author = {Brunet, Claude},
	editor = {Fruyt, Michèle and Van Laer, Sophie},
	year = {2008},
	pages = {101--113}
}

@incollection{christol_entre_2008,
	address = {Paris},
	edition = {L'Harmattan},
	series = {Série {Grammaire} et {Linguistique}, {Collection} {KUBABA}},
	title = {Entre adverbes et adjectifs},
	number = {2},
	booktitle = {Adverbes et évolution linfuistique en latin},
	author = {Christol, Alain},
	editor = {Fruyt, Michèle and Van Laer, Sophie},
	year = {2008},
	pages = {69--81},
}


@incollection{meillet_levolution_1922,
	address = {Paris},
	title = {L’évolution des formes grammaticales},
	shorttitle = {L’évolution des formes grammaticales},
	url = {https://archive.org/details/linguistiquehist00meil/page/130/mode/2up},
	booktitle = {linguistique historique et linguistique générale},
	publisher = {Champion},
	author = {Meillet, Antoine},
	year = {1922},
	note = {Article publié pour la première fois sur Scientia (Rivista di scienza), vol. XII (1912) , n*XXVI, 6},
	pages = {130--148}
}


@article{passarotti_interlinking_2020,
	title = {Interlinking through {Lemmas}. {The} {Lexical} {Collection} of the {LiLa} {Knowledge} {Base} of {Linguistic} {Resources} for {Latin}},
	volume = {58},
	copyright = {Copyright (c) 2020 Studi e Saggi Linguistici},
	issn = {0085-6827},
	url = {https://www.studiesaggilinguistici.it/index.php/ssl/article/view/277},
	doi = {10.4454/ssl.v58i1.277},
	abstract = {This paper presents the structure of the LiLa Knowledge Base, i.e. a collection of multifarious linguistic resources for Latin described with the same vocabulary of knowledge description and interlinked according to the principles of the so-called Linked Data paradigm. Following its highly lexically based nature, the core of the LiLa Knowledge Base consists of a large collection of Latin lemmas, serving as the backbone to achieve interoperability between the resources, by linking all those entries in lexical resources and tokens in corpora that point to the same lemma. After detailing the architecture supporting LiLa, the paper particularly focusses on how we approach the challenges raised by harmonizing different strategies of lemmatization that can be found in linguistic resources for Latin. As an example of the process to connect a linguistic resource to LiLa, the inclusion in the Knowledge Base of a dependency treebank is described and evaluated.},
	language = {en},
	number = {1},
	urldate = {2020-11-20},
	journal = {Studi e Saggi Linguistici},
	author = {Passarotti, Marco and Mambrini, Francesco and Franzini, Greta and Cecchini, Flavio Massimiliano and Litta, Eleonora and Moretti, Giovanni and Ruffolo, Paolo and Sprugnoli, Rachele},
	month = sep,
	year = {2020},
	note = {Number: 1},
	keywords = {interoperability, Latin, lemmatization, linguistic linked open data, linguistic resources},
	pages = {177--212},
	file = {Full Text PDF:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/ZJBX6LVA/Passarotti et al. - 2020 - Interlinking through Lemmas. The Lexical Collectio.pdf:application/pdf;Snapshot:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/X77QIYPD/277.html:text/html;Snapshot:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/WQWIU5MC/277.html:text/html}
}

@article{sturtevant_monophthongization_1916,
	title = {The {Monophthongization} of {Latin} ae},
	volume = {47},
	issn = {0065-9711},
	url = {https://www.jstor.org/stable/282830},
	doi = {10.2307/282830},
	urldate = {2020-11-24},
	journal = {Transactions and Proceedings of the American Philological Association},
	author = {Sturtevant, Edgar H.},
	year = {1916},
	note = {Publisher: [Johns Hopkins University Press, American Philological Association]},
	pages = {107--116}
}



@misc{srinidhi_lemmatization_2020,
	title = {Lemmatization in {Natural} {Language} {Processing} ({NLP}) and {Machine} {Learning}},
	url = {https://towardsdatascience.com/lemmatization-in-natural-language-processing-nlp-and-machine-learning-a4416f69a7b6},
	abstract = {Lemmatization is one of the most common text pre-processing techniques used in Natural Language Processing (NLP) and machine learning in…},
	language = {en},
	urldate = {2020-12-07},
	journal = {Medium},
	author = {Srinidhi, Sunny},
	month = may,
	year = {2020},
	file = {Snapshot:/home/thibault/.mozilla/firefox/dqyoiprc.default/zotero/storage/ZCLE46J5/lemmatization-in-natural-language-processing-nlp-and-machine-learning-a4416f69a7b6.html:text/html}
}

@inproceedings{heiden:halshs-00549779,
  TITLE = {{TXM : Une plateforme logicielle open-source pour la textom{\'e}trie - conception et d{\'e}veloppement}},
  AUTHOR = {Heiden, Serge and Magu{\'e}, Jean-Philippe and Pincemin, B{\'e}n{\'e}dicte},
  URL = {https://halshs.archives-ouvertes.fr/halshs-00549779},
  BOOKTITLE = {{10th International Conference on the Statistical Analysis of Textual Data - JADT 2010}},
  ADDRESS = {Rome, Italy},
  EDITOR = {Sergio Bolasco and Isabella Chiari and Luca Giuliano},
  PUBLISHER = {{Edizioni Universitarie di Lettere Economia Diritto}},
  VOLUME = {2},
  NUMBER = {3},
  PAGES = {1021-1032},
  YEAR = {2010},
  MONTH = Jun,
  KEYWORDS = {textometry ; full text search engine ; statistical analysis ; natural language processing ; grails framework ; textom{\'e}trie ; open-source ; framework grails ; traitement automatique de la langue ; tal ; eclipse rcp ; analyse statistique ; moteur de recherche plein texte ; xml-tei},
  PDF = {https://halshs.archives-ouvertes.fr/halshs-00549779/file/Heiden_al_jadt2010.pdf},
  HAL_ID = {halshs-00549779},
  HAL_VERSION = {v1},
}


@software{thibault_clerice_2018_1243076,
  author       = {Thibault Clérice},
  title        = {PonteIneptique/collatinus-python: 0.1.6},
  month        = may,
  year         = 2018,
  publisher    = {Zenodo},
  version      = {0.1.6},
  doi          = {10.5281/zenodo.1243076},
  url          = {https://doi.org/10.5281/zenodo.1243076}
}


@misc{wright_new_2019,
	title = {New {Deep} {Learning} {Optimizer}, {Ranger}: {Synergistic} combination of {RAdam} + {LookAhead} for the best of…},
	shorttitle = {New {Deep} {Learning} {Optimizer}, {Ranger}},
	url = {https://medium.com/@lessw/new-deep-learning-optimizer-ranger-synergistic-combination-of-radam-lookahead-for-the-best-of-2dc83f79a48d},
	abstract = {A new paper in part by the famed deep learning researcher Geoffrey Hinton introduces the LookAhead optimizer(“LookAhead optimizer: k steps…},
	language = {en},
	urldate = {2020-12-22},
	journal = {Medium},
	author = {Wright, Less},
	month = sep,
	year = {2019},
	file = {Snapshot:/home/thibault/Zotero/storage/9VKRJ2QP/new-deep-learning-optimizer-ranger-synergistic-combination-of-radam-lookahead-for-the-best-of-2.html:text/html}
}


@misc{clerice_allow_nodate,
	title = {Allow for using other {Learning} {Rate} {Schedulers} and {Optimizers} · {Issue} \#76 · emanjavacas/pie},
	url = {https://github.com/emanjavacas/pie/issues/76},
	language = {en},
	urldate = {2020-12-22},
	year = 2020,
	month = november,
	journal = {GitHub},
	author = {Clérice, Thibault and Manjavacas, Enrique},
	file = {Snapshot:/home/thibault/Zotero/storage/PM5QHVZQ/76.html:text/html}
}
