\section{Principes généraux du \textit{deep learning} liés au TAL}

Les statistiques ont intéressé relativement tôt plusieurs branches des sciences humaines, dont celles du domaine classique avec l'histoire quantitative ou la linguistique de corpus. Les statistiques ont alors un rôle relativement simple: permettre d'observer des phénomènes à distance du texte ou des données récoltées par l'histoire, et établir ainsi des règles par exemple. On peut citer comme exemple UN TRAVAIL UTILISANT LA STATISTIQUE SUR L'ORDRE SVO EN FRANCAIS (?). Depuis maintenant plusieurs décénnies, on s'est aussi rendu compte dans ces mêmes domaines que les mathématiques et l'informatique offraient d'autres possibilités, en particulier ce que l'on appelle l'\textit{apprentissage machine} (\textit{machine learning}): il devient possible d'apprendre à la machine à faire des tâches percues comme répétitives par l'être humain, comme la reconnaissance des noms propres dans un texte. Pour faire cela, on a recours à un ensemble d'algorithmes mathématiques, qui, en voyant des données, vont reconnaître comme l'être humain des motifs permettant de classer des choses. Pour reprendre l'exemple des noms propres, le premier indice sera souvent une majuscule: c'est un premier motif validant l'hypothèse.

L'apprentissage machine commence par l'entraînement: il faut donner à la machine des données, lui dire quelle est la réponse attendue. C'est le même phénomène avec les enfants en bas âge et l'acquisition du langage: à force de répéter que ceci est une voiture, l'enfant intègre "Machine à 4 Roues"=Voiture. La machine va pendant cette entraînement modifier les variables qui constituent son modèle mathématique: en somme, c'est toujours la même formule qui est appliquée, mais la machine va décider au fur et à mesure de l'importance de telle ou telle information. Par exemple, pour les noms propres, elle comprendra peu à peu que l'information position dans la phrase et majuscule à l'initiale sont très importante, tandis que les suffixes ne le sont pas forcément... Ces valeurs de variables de l'algorithme sont appelées \textit{poids} ou \textit{paramètres} et constituent une retranscription mathématique de ce que la machine à appris. 

\begin{figure}
    \centering
    \begin{equation*}
        \begin{matrix}
            \textrm{\textit{Mot à classer}} \\
            \begin{bmatrix}
            \textrm{Commence par une majuscule} \\
            \textrm{Premier mot dans la phrase} \\
            \textrm{Précédé d'une préposition} \\
            \textrm{...} \\
            \end{bmatrix}
        \end{matrix}
        \rightarrow
        \begin{matrix}
            \textrm{Fortissimi sunt Belgae} \\
            \begin{bmatrix}
            1 & 0 & 1 \\
            1 & 0 & 0 \\
            0 & 0 & 0 \\
            & \textrm{...} & \\
            \end{bmatrix}
        \end{matrix}
        \rightarrow Algorithme \rightarrow
        \begin{matrix}
            \textrm{Résultat} \\
            \begin{bmatrix}
            0 & 0 & 1 \\
            \end{bmatrix}
        \end{matrix}
        \end{equation*}
    \caption{Exemple de représentation de la phrase "Fortissimi sunt Belgae.". Les trois colonnes représentent les données, les lignes représentes des variables (on parle aussi de \textit{features}). Le résultat est une matrice à une seule dimension (un vecteur) comprenant 1 pour les noms propres, et 0 pour les autres.}
    \label{fig:deep-learning:matrice}
\end{figure}

Pour représenter les données, et pour effectuer des calculs dessus, l'apprentissage machine se base sur l'algèbre linéaire: cette partie des mathématiques se fonde sur le calcul de matrices, des modélisations de données en plusieurs dimensions. Pour faire simple, au lieu d'effectuer des calculs sur des nombres un par un, on établit des calculs sur des ensembles de nombres dont la traduction dans nos habitude la plus simple serait un tableau (\textit{cf.} Table \ref{fig:deep-learning:matrice}). En effet, un tableau, avec x colonnes et y lignes est tout simplement une matrice à 2 dimension (x, y). 

En traitement automatique des langues, on a recourt à l'apprentissage machine pour deux grands types de tâches:
\begin{itemize}
    \item \textbf{La classification} de valeurs. Il peut s'agir de chercher à annoter des mots comme noms propres, comme adjectifs, comme sujet, etc. ou encore de classer des phrases par thèmes ou des textes par auteurs.
    \item \textbf{La génération} de texte. Elle est désormais commune dans la traduction automatique, mais aussi dans la création de robot de discussion pour les plateformes en ligne. On distinguera les générations caractère par caractère des générations mot par mot, qui possèdent des facultés différentes: la possibilité pour l'une de trouver de nouvelles formes morphologiques, pour l'autre, l'impossibilité de proposer un mot inexistant.
\end{itemize}{}

En pleine croissance depuis une dizaine d'années, l'apprentissage profond se distingue dans l'apprentissage machine principalement sur deux points: d'une part, l'absence de nécessité pour le développement d'un modèle de faire le tri manuellement parmi les données à prendre en compte (on parle d'absence de \textit{feature extraction}; d'autres parts, parce que la machine récupère beaucoup plus de données, elle a besoin d'une architecture mathématique plus complexe et de beaucoup plus de puissance de calcul. Certaines tâches, comme l'attribution d'auteur, existent à la fois comme tâche classique et comme tâche d'apprentissage profond. En apprentissage machine "classique", on sélectionne entre autres les mots les plus fréquents de la langue, les mots outils (déterminants, verbes d'état, conjonctions de coordinations, etc.) et on récupère leur fréquence dans chaque texte à classer\footnote{Il existe bien d'autres paramètres utilisables, \textit{cf.} \cite{Cafieroeaax5489}}. Dans le domaine latin, en poésie latine pour être précis, les formations rythmiques\footcite{nagy_metre_nodate} ont pu être utilisé comme variables d'entrée et produire des résultats très pertinents. Au contraire, en apprentissage profond, on aura tendance à fournir le texte de manière brute ou un minimum prétraité (selon que l'on s'intéresse aux caractères plutôt qu'aux mots). C'est par exemple le procédé proposé par Ruder et al. \footcite{ruder_character-level_2016} dans une étude sur l'attribution d'auteurs sur twitter: pour gérer des textes courts, avec des orthographes variées, leur proposition fut de prendre le texte brut et de traiter les caractères en brut comme données d'entraînement: au machine de faire le travail pour identifier les motifs importants.

L'apprentissage machine se divise par ailleurs en deux autres grandes catégories, applicables à l'apprentissage profond: l'apprentissage non supervisé et l'apprentissage supervisé. Tout comme l'humain, la machine est capable d'apprendre par comparaison d'elle-même: si un objet possède quatre roues, des portes, il est probable qu'il s'agisse de la même chose, les camions et les voitures possèdent donc une proximité. Mais tout comme l'être humain, elle peut aussi apprendre par injonction et correction: oui une vache et un cheval se ressemblent, mais ceci est un cheval, et ceci est une vache. La différence fondamentale entre les deux protocoles réside dans la présence ou l'absence dans les données fournies pour l'entraînement d'étiquettes correspondant aux résultats attendus en sortie. L'apprentissage non-supervisé va effectuer des rapprochements entre les données: en traduction automatique, la machine repèrera facilement que la présence \textit{est} se traduira par une présence de \textit{is}. Les apprentissages non supervisés sont principalement utilisés, en traitement automatique du langage et en apprentissage profond, pour créer des corpus: on le retrouve par exemple sur des agrégateurs tels que \textit{Google News} où les articles sont rassemblés par thème en fonction de la proximité de leur sujet. Il n'y a pas - ou peu - d'éditorialisation humaine dans ce genre de procédé. Au contraire, en apprentissage supervisé, on donnera à la machine à reconnaître Molière de Corneille en lui disant: ce texte est de Corneille, ce texte est de Molière, etc... 

Pour être précis, en apprentissage supervisé, la machine joue en quelque sorte à un jeu de chaud et froid avec les données: à chaque fois qu'elle donne une réponse, elle est comparée à la réponse attendue. L'écart entre ces réponses est une mesure mathématique appelée \textit{loss} (perte). Cette perte est d'ailleurs transmise à l'algorithme pour affiner ses poids, et il a alors pour objectif de réduire cette dernière le plus possible: on appelle cela la \textit{rétropropagation} (\textit{backpropagation}). Un entraînement peut voir les données plusieurs fois: on appellera ces cycles de consultation des \textit{epochs} (époques). La répétition, encore une fois, comme avec un enfant en bas âge, permet à la machine d'enfin comprendre les motifs et à proposer les réponses attendues en lui laissant le temps nécessaire à apprendre. Une fois le modèle entraîné, il peut être utilisé sur des données sans réponse connue: on parle alors d'inférence ou de prédiction, et le modèle n'apprend plus.

\begin{table}[]
\centering
\begin{tabular}{lllccc}
\toprule
\multirow{2}{*}{Texte} & \multirow{2}{*}{Classe} & \multirow{2}{*}{Prédiction} & \multicolumn{3}{l}{Catégorie de classification} \\
                       &                         &                             & Corneille        & Molière       & Racine       \\ \midrule
Le Cid                 & Corneille               & Corneille                   & VP               & VN            & VN           \\
Le Misanthrope         & Molière                 & Molière                     & VN               & VP            & VN           \\
Phèdre                 & Racine                  & Racine                      & VN               & VN            & VP           \\
L'Avare                & Molière                 & Racine                      & VN               & FN            & FP          \\ \bottomrule
\end{tabular}
\caption{Exemple de classification avec les catégories afférentes. VP = Vrai Positif, FP = Faux Positif, VN = Vrai Négatif, FN = Faux Négatif}
\label{deep-learning:table:true-positives}
\end{table}

Pour mesurer l'efficacité d'un modèle supervisé, on le teste. Pour cela, on coupe généralement un corpus de données entre des données d'entraînement (\textit{train data}) et de test (\textit{test data}). On compare ensuite chacune des prédictions du modèle obtenu avec les étiquettes données dans le corpus, que l'on appelle vérité de terrain (\textit{ground truth}). Les étiquettes sont regroupées en classes: par exemple, dans le cas de Molière et Corneille, nous avons deux classes, et si nous avons 128 textes, nous avons 128 étiquettes réparties entre ces deux classes. Les résultats sont regroupés ensuite dans 4 catégories (\textit{cf.} \ref{deep-learning:table:true-positives}): les vrais positifs (VP/TP, bonne étiquette), faux positifs (FN, mauvaise étiquette pour la classe actuelle), vrais négatifs (VN/TN, reconnu comme n'étant pas de cette étiquette), faux négatif (FN, étiquette de la classe actuelle non reconnue); si toutes les étiquettes sont dans les catégories qualifiées de vraies, le modèle n'a fait aucune erreur. Ces écarts à la vérité sont mesurés principalement par 4 formules:
\begin{itemize}
    \item L'\textit{accuracy}\footnote{Le choix a été fait de ne jamais traduire \textit{accuracy} en raison de sa traduction en "précision" qui crée la confusion avec l'autre mesure \textit{precision}} mesure le nombre de vrais positifs sur le nombre total d'éléments annotés, et on pourrait le ramener à un pourcentage classique de bonne réponse. En machine learning, on le définit aussi par la formule correspondante $accuracy = \frac{VP + VN}{VP + VN + FP + FN}$
    \item La \textit{precision} mesure le pourcentage de bonnes réponses par classe sur l'ensemble des attributions effectuées sur cette classe. Elle favorise les attributions correctes à une classe sans prendre en compte les non-attributions. Sa formule est $precision = \frac{VP}{VP + FP}$
    \item Le \textit{recall} (rappel) mesure le pourcentage de réponses correctes sur l'ensemble de la classe. Elle favorise la reconnaissance de chacune des classes plutôt que les mauvaises attributions. Sa formule est $recall = \frac{VP}{VP+FN}$.
    \item Le F-Score (qui peut se découper en F1-, F2-, etc.) est la moyenne harmonique de la précision et du rappel, offrant ainsi une mesure intermédiaire. Sa formule est $F1 = \frac{2 \cdot precision\cdot recall}{precision+ recall}$
\end{itemize}{}

\label{deep-learning:overfitting}
Un risque de l'entraînement est de se retrouver avec un modèle qui apprend les réponses par coeur pour chaque donnée d'entrée: à ce moment là, il sera incapable de gérer des données extérieures. Une des sources du problème peut-être un corpus d'entraînement trop homogène: la catégorie nom propre ne comprend que les noms Alexis et Marcus, la machine apprend qu'un nom propre est forcément Alexis ou Marcus. On appelle cela un phénomène de \textit{surspécialisation} (\textit{overfitting}) au corpus d'entraînement. Sans que cela soit toujours le cas, une \textit{accuracy} à 100\% sur un corpus d'entraînement ou une loss de 0 est souvent l'un de ses signes. Pour éviter cela, on peut faire appel à plusieurs stratégies, non exclusives:
\begin{itemize}
    \item l'utilisation d'un corpus de développement ou d'évaluation (\textit{dev/eval corpus}). Il est vu lors de l'entraînement, mais n'est pas utilisé pour l'apprentissage: les erreurs ne sont pas individuellement transmises à l'algorithme. Cependant, sa perte, ou toute mesure sélectionnée dans ce cadre sont utilisées comme grand indicateur de fonctionnement: si le corpus d'entraînement fait 100\%, mais que le corpus de développement fait 80\%, on indiquera au modèle qu'il faut continuer à apprendre, quitte à s'éloigner des 100\%.
    \item l'utilisation, dans l'architecture du modèle, de \textit{dropout}, c'est-à-dire la suppression aléatoire d'une partie des données d'entraînement à chaque époque. En traitement automatique de la langue, il s'agit principalement de supprimer un mot par exemple. Cela correspondrait, dans une situation humaine, à donner des photographies d'animaux à trou (sans tête, sans jambes, etc.) afin que l'enfant reconnaisse les autres traits de l'animal. % glauque non ?
\end{itemize}

Enfin, on parle ici et là d'hyperparamètres d'architecture: il s'agit principalement de variables de configuration qui, pour un modèle, changent l'architecture ou sa manière de s'entraîner. L'un d'eux, très commun, est nommé \textit{learning rate}: il s'agit d'un nombre (principalement un décimal, de type 0.001) qui sert de pas pour corriger les erreurs du modèle. Plus il est bas, plus le modèle met de temps à apprendre; plus il est haut, plus le modèle risque de rater la bonne direction d'apprentissage. D'autres hyperparamètres concernent généralement la taille des réseaux neuronaux qui composent l'architecture. 

On retrouve en traitement automatique des langues quelques modules d'architecture très communs que l'on se propose d'expliquer, en partie, ici. Ces modules sont très souvent combinés ensemble: il est rare de voir une architecture complètement basée sur un seul de ces éléments.

\subsection{Embeddings}
\label{deep-learning:embeddings}

Une première difficulté pour la machine est de comprendre ce qu'est un mot. Puisque la machine, pour son calcul, doit opérer par nombres, la première option est donc de dire: à chaque mot, un chiffre. Si l'on a deux phrases, par exemple "\textit{fortissimi sunt belgae}" et "\textit{timendi sunt belgae}", à chaque mot nouveau un chiffre serait attribué, et l'on donnerait à l'algorithme les nombres 1, 2 et 3 puis 4, 2, 3: 2 et 3 sont présents deux fois, on ne réattribue pas d'identifiant numérique à \textit{sunt} et \textit{belgae}, par contre, \textit{timendi} qui est nouveau poussera à la création d'un nouvel identifiant, 4. On appelle ces nombres valeurs symboliques, et le résultat final \textit{one-hot vector}. Enfin, l'index des mots est considérée comme une variable discrète: son nombre de possibilitées est fini (on peut les énumérer)\footnote{Une variable discrète est une variable dont on peut énumérer les valeurs (1, 2, 3, 4, etc.). par opposition à une variable continue (0.000000001, 0.000000002, etc.)}. 

Malheureusement pour la machine, ce caractère discret de la variable rend très difficile de faire un rapprochement entre 4 (timendi) et 1 (fortissimi): ils n'ont mathématiquement rien à voir ensemble. L'intuition est donc de dire: représentons sur plusieurs colonnes des propriétés de mots. Par exemple, sur une échelle de 0 à 1, 0 étant un verbe, 1 un nom, 0.5 un adjectif, où se situe timendi ? On appelle ce phénomène mathématique une projection sur X dimensions, X étant le nombre de ces colonnes. Bien sûr, ces colonnes ne sont pas aussi simplement lisibles mais font suffisament sens pour que la machine en fasse usage: cette représentation que la machine construit est un module de réseau que l'on appelle \textit{embeddings}. 

Au fur et à mesure de l'apprentissage, la machine fige alors une représentation de chacun des mots qui sera utile au reste du réseau (\textit{cf.} Figure \ref{deep-learning:embeddings}). Dans l'exemple précédent, on établit une matrice de $N$ par $M$, où $N$ correspond au nombre de mots différents rencontrés (ici 4) et $M$ une dimension de projection choisie (ici 2). La matrice d'embeddings, si l'on avait par exemple un apprentissage en vu d'une classification par sens ou d'une classification par nature de mot, aura tendance à proposer des résultats tels que dans la figure précédente, avec un rapprochement évident pour l'être humain mais aussi désormais pour la machine de \textit{timendi} et \textit{fortissimi}. La machine apprend alors à reconnaître des éléments par leur contexte: pour des mots, ce principe repose sur le principe de distributionnalité\footcite{firth_papers_1957} qui veut que deux mots se ressemblant (sémantiquement, syntaxiquement, etc.) auront le même contexte\footnote{Nous proposons une étude de ce qu'apprend l'algorithme en fonction de la tâche en \ref{subsec:lemma_resultats}.}

\input{tex_figures/1-x-deep-learning/one-hot}

\input{tex_figures/1-x-deep-learning/embedding}

Bien sûr, les dimensions des embeddings sont ordinairement beaucoup plus grandes que dans l'exemple construit ici: David Bamman, lors de la création d'une telle matrice sur l'ensemble des mots présents dans les livres classés langue latine du site archives.org\footcite{bamman_11k_2012}, a créé une matrice de $N=2,961,867$ et de $M=100$ (100 est une dimension assez habituelle pour $M$). 

\subsection{Linéaires}

Si les \textit{embeddings} permettent de générer une représentation des données, les modèles \textit{linéaires}\footnote{On le retrouve sous plusieurs noms: \textit{perceptron}, \textit{linear network}, \textit{dense layer}, \textit{régression linéaire}, etc.} permettent de les classer. Il s'agit de la forme la plus simple de réseau neuronal (\textit{cf.} figure \ref{deep-learning:simple-linear}). 

Cette couche linéaire peut être accumulée à d'autres couches linéaires, souvent en réduisant peu à peu la taille du réseau jusqu'à arriver à la taille de sortie: cela s'appelle un \textit{perceptron multi-couches}. Par exemple, pour un classement de texte par auteur, on pourrait créer un réseau utilisant les fréquences de chacun des mots (fréquence de "fortissimi", "belgae", etc. dans chacun des textes) et qui viendrait réduire, sur plusieurs couches, la taile de la matrice jusqu'à obtenir la taille des réponses possibles. Ce réseau est appelé perceptron multi-couche (\textit{multi-layer perceptron}) et constitue le réseau neuronal le plus simple possible (\textit{cf.} figure \ref{deep-learning:mlp}). Dans une telle situation, les couches intermédiaires sont appelées \textit{hidden layers}. Son principe de réduction des dimensions peut-être appliqué aussi à des sorties d'autres modules avant la classification finale.

Les couches linéaires prennent une forme très simple. Dans le cadre d'un vecteur de fréquence comme dans la figure \ref{deep-learning:mlp}, le perceptron prend une matrice de taille $M$ par 1 (le vecteur) et ressort une matrice de taille $M...O$ où $O$ est le nombre d'auteurs. Sur ce vecteur, le modèle applique une formule particulièrement simple: il s'agit d'une fonction affine. Chaque valeur $M_{i}$ (ici, $i$ est un index de mot) et pour chaque classe de sortie notée $j$  un poids $w_{i}{j}$ existe en plus d'une variable partagée par chaque noeud appelée biais ($b_{j}$) telle que $f(X, j) = W_{j} \dot X + b_{j}$  où X est la matrice de données fournie\footnote{En algèbre linéraire, une multiplication de matrice A, de taille N par M, par une matrice B, de taille M par P, résulte en une matrice de taille N par P: une multiplication peut donc réduire la taille de la matrice.}.

\begin{figure}
    \centering
    \includegraphics[width=5cm]{results/deep-learning/explanations/SimpleLinear.png}
    \caption{Exemple de couche linéaire (simplifiée)}
    \label{deep-learning:simple-linear}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{results/deep-learning/explanations/MLP.png}
    \caption{Exemple de perceptron multi-couches. Le réseau construit ici possède une entrée de taille N, une sortie de 2, et un réseau $Linear(N, L1_N) \rightarrow Linear(L1_N, L2_N) \rightarrow Linear(L2_N, 2)$}
    \label{deep-learning:mlp}
\end{figure}

\subsection{RNN: LSTM et GRU}

Malheureusement, les couches linéaires posent un problème, en particulier pour les TALs et le traitement d'image: il ne traitent pas vraiment les données en séries. Les perceptrons multi-couches ne gèrent en effet l'ensemble des données comme des variables indépendantes, non-séquentielles. On appelle ce type de réseau \textit{feed-forward} (propagation directe). Pour traiter des données en séries, on s'est d'abord tourner vers d'autres types de réseaux, appelés \textit{réseaux neuronaux acycliques (recurrent neural networks, RNN)}. Les réseaux récurrents ont la particularité de traiter les données en séries, et de réutiliser l'analyse de chaque élément pour l'analyse de l'élément suivant, comme le montre le schéma.

\subsection{CNN}