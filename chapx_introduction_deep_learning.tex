\section{Principes généraux du \textit{deep learning} liés au TAL}

L'apprentissage profond, ou \textit{deep learning}, est une sous-catégorie de ce que l'on appelle l'apprentissage machine. L'apprentissage machine est une branche des mathématiques et de l'informatique. Lors de la consommation de données, que l'on appelle entraînement, les algorithmes de ce domaine, par le biais des outils qui les implémentent, apprennent des motifs mathématiques permettant l'analyse ou la création de nouveaux contenus. L'apprentissage machine est fondé principalement sur l'algèbre linéaire, branche des mathématiques qui concernent les matrices et les vecteurs\footnote{Les matrices sont des arrangements de nombres dont la forme la plus simple à décrire serait un tableau: ainsi, un tableau [[0 1] [2 3]] comprenant 2x2 entrées est une matrice à deux dimensions. Un vecteur est un cas particulier de matrice unidimensionnelle.}. Il existe plusieurs types de tâches, mais, en traitement automatique des langues, deux ont une place plus importante que les autres:

\begin{itemize}
    \item \textbf{La classification} de valeurs. Il peut s'agir de chercher à annoter des mots comme entités nommées par exemple, d'annoter des caractères comme caractère de fin de mot dans le cadre de \textit{scripta continua}, ou encore de classer des phrases ou des textes comme portant sur tel sujet ou étant écrits par tel auteur.
    \item \textbf{La génération} de texte. Elle est désormais commune dans la traduction automatique, mais aussi dans la création de robot de discussion pour les plateformes en ligne. On distinguera les générations caractère par caractère des générations mot par mot, qui possèdent des facultés différentes: la possibilité pour l'une de trouver de nouvelles formes morphologiques, pour l'autre, l'impossibilité de proposer un mot inexistant.
\end{itemize}{}

L'apprentissage profond se distingue dans l'apprentissage machine principalement par l'absence de nécessité pour le développement d'un modèle de faire le tri manuellement parmi les données à prendre en compte statistiquement: on parle d'absence de \textit{feature extraction}. Prenons l'exemple de l'attribution d'auteur. En apprentissage machine "classique", on sélectionne entre autres l'occurrence des mots vides, l'ordre de trigramme de POS(\textit{cf.} \ref{subsec:lemma_intro})\footcite{Cafieroeaax5489}, ou encore, en poésie latine par exemple, les formations rythmiques\footcite{nagy_metre_nodate}. Au contraire, en apprentissage profond, on aura tendance à fournir le texte de manière brute ou un minimum prétraité (selon que l'on s'intéresse aux caractères plutôt qu'aux mots). C'est par exemple le procédé proposé par Ruder et al. \footcite{ruder_character-level_2016} dans une étude sur l'attribution d'auteur sur twitter: pour gérer des textes courts, avec des orthographes variées, leur proposition fut de prendre le texte brut et de traiter les caractères dans leurs séquences comme données d'entraînement.

On distingue en apprentissage machine deux grandes catégories: l'apprentissage supervisé et l'apprentissage non supervisé.  La différence fondamentale entre les deux protocoles réside dans la présence dans les données fournies pour l'entraînement d'étiquettes correspondant aux résultats attendus en sortie: c'est à force de voir sunt annoté comme lemme "est" qu'il est capable de le produire de lui-même, à l'image d'un enfant à qui l'on apprend à reconnaître des animaux par exemple. En apprentissage supervisé, on peut entraîner la machine à reconnaître Molière de Corneille en lui disant: ce texte est de Corneille, ce texte est de Molière. En apprentissage non supervisé, on peut laisser la machine créer ces groupes d'elle-même, et il sera de la responsabilité de l'utilisateur d'en faire une analyse. Les apprentissages non supervisés sont principalement utilisés, en traitement automatique du langage, pour créer des corpus: on le retrouve par exemple sur des agrégateurs tels que Google News où les articles sont rassemblés par thème en fonction de la proximité de leur sujet. Il n'y a pas - ou peu - d'éditorialisation humaine dans ce genre de procédé. On le retrouve aussi dans les embeddings (\textit{cf.} \ref{deep-learning:embeddings}).

En apprentissage machine, on sépare de l'entraînement l'inférence (ou prédiction): le premier permet de constituer un modèle, avec des poids (variables apprises automatiquement par celui-ci) tandis que la seconde correspond à l'utilisation de ces poids sur des données nouvelles, sans apprentissage associé par la machine (elle n'apprend plus). Durant l'entraînement, le modèle cherche à s'approcher le plus possible du résultat attendu: la différence entre les bonnes réponses et la réponse proposée est une mesure mathématique appelée \textit{loss} (perte). Cette perte est d'ailleurs transmise au modèle pour affiner son modèle, et l'algorithme a alors pour objectif de réduire celle-ci le plus possible. Un entraînement peut voir les données plusieurs fois: on appellera ces cycles de consultation des \textit{epochs} (époques). La répétition, encore une fois, comme avec un enfant en bas âge, permet à la machine d'enfin comprendre les motifs et à proposer les réponses attendues. 

\begin{table}[]
\centering
\begin{tabular}{lllccc}
\toprule
\multirow{2}{*}{Texte} & \multirow{2}{*}{Classe} & \multirow{2}{*}{Prédiction} & \multicolumn{3}{l}{Catégorie de classification} \\
                       &                         &                             & Corneille        & Molière       & Racine       \\ \midrule
Le Cid                 & Corneille               & Corneille                   & VP               & VN            & VN           \\
Le Misanthrope         & Molière                 & Molière                     & VN               & VP            & VN           \\
Phèdre                 & Racine                  & Racine                      & VN               & VN            & VP           \\
L'Avare                & Molière                 & Racine                      & VN               & FN            & FP          \\ \bottomrule
\end{tabular}
\caption{Exemple de classification avec les catégories afférentes. VP = Vrai Positif, FP = Faux Positif, VN = Vrai Négatif, FN = Faux Négatif}
\label{deep-learning:table:true-positives}
\end{table}

Pour mesurer l'efficacité d'un modèle supervisé, on doit le tester. Pour cela, on coupe généralement un corpus de données entre des données d'entraînement (\textit{train data}) et de test (\textit{test data}). On compare ensuite chacune des prédictions du modèle obtenu avec les étiquettes données dans le corpus, que l'on appelle vérité de terrain (\textit{ground truth}). Les étiquettes sont regroupées en classes: par exemple, dans le cas de Molière et Corneille, nous avons deux classes, mais si nous avons 128 textes, nous avons 128 étiquettes comprenant ces deux classes. Les résultats sont regroupés ensuite dans 4 catégories (\textit{cf.} \ref{deep-learning:table:true-positives}): les vrais positifs (bonne étiquette), faux positifs (mauvaise étiquette pour la classe actuelle), vrais négatifs (reconnu comme n'étant pas de cette étiquette), faux négatif (étiquette de la classe actuelle non reconnue); si toutes les étiquettes sont dans les catégories qualifiées de vraies, le modèle n'a fait aucune erreur. Ces écarts à la vérité sont mesurés principalement par 4 formules:
\begin{itemize}
    \item L'\textit{accuracy}\footnote{Le choix a été fait de ne jamais traduire \textit{accuracy} en raison de sa traduction en "précision" qui crée la confusion avec l'autre mesure \textit{precision}} mesure le nombre de vrais positifs sur le nombre total d'éléments annotés, et on pourrait le ramener à un pourcentage classique de bonne réponse. En machine learning, on le définit aussi par la formule correspondante $accuracy = \frac{TP + TN}{TP + TN + FP + FN}$
    \item La \textit{precision} mesure le pourcentage de bonne réponse par classe sur l'ensemble des attributions effectuées sur cette classe. Elle favorise les attributions correctes à une classe sans prendre en compte les non-attributions. Sa formule est $precision = \frac{TP}{TP + FP}$
    \item Le \textit{recall} (rappel) mesure le pourcentage de réponse correcte sur l'ensemble de la classe. Elle favorise la reconnaissance de chacune des classes plutôt que les mauvaises attributions. Sa formule est $recall = \frac{TP}{TP+FN}$.
    \item Le F-Score (qui peut se découper en F1-, F2-, etc.) est la moyenne harmonique de la précision et du rappel, offrant ainsi une mesure mélangeant les deux. Sa formule est $F1 = \frac{2 \cdot precision\cdot recall}{precision+ recall}$
\end{itemize}{}

Par ailleurs, ces mesures permettent non seulement de mesurer l'efficacité d'un modèle, mais appliquées à des corpus de tests, elles permettent aussi de mesurer sa surspécialisation\label{deep-learning:overfitting} (\textit{overfitting}) au corpus d'entraînement. La surspécialisation correspond, à cause d'un corpus entraînement ou d'une architecture de modèle, à une incapacité du modèle de faire des prédictions en dehors de ce corpus d'origine. Sans que cela soit toujours le cas, une \textit{accuracy} à 100\% sur un corpus d'entraînement ou une loss de 0 est souvent l'un de ses signes. Pour éviter cela, on peut faire appel à plusieurs stratégies:
\begin{itemize}
    \item l'utilisation d'un corpus de développement ou d'évaluation (\textit{dev/eval corpus}). Il est vu lors de l'entraînement, mais n'est pas utilisé pour l'apprentissage: les erreurs ne sont pas individuellement transmises à l'algorithme. Cependant, sa perte, ou toute mesure sélectionnée dans ce cadre sont utilisées comme grand indicateur de fonctionnement: si le corpus d'entraînement fait 100\%, mais que le corpus de développement fait 80\%, on indiquera au modèle qu'il faut continuer à apprendre, quitte à s'éloigner des 100\%.
    \item l'utilisation, dans l'architecture du modèle, de \textit{dropout}, c'est-à-dire la suppression aléatoire d'une partie des données d'entraînement à chaque époque. En traitement automatique de la langue, il s'agit principalement de supprimer un mot par exemple. Cela correspondrait, dans une situation humaine, à donner des photographies d'animaux à trou (sans tête, sans jambes, etc.) afin que l'enfant reconnaisse les autres traits de l'animal. % glauque non ?
\end{itemize}

Enfin, on parle ici et là d'hyperparamètres d'architecture: il s'agit principalement de nombres qui, pour un modèle, changent l'architecture ou sa manière de s'entraîner. L'un d'eux, très commun, est nommé \textit{learning rate}: il s'agit un nombre (principalement un décimal, de type 0.001) qui sert de pas pour corriger les erreurs du modèle. Plus il est bas, plus le modèle met de temps à apprendre; plus il est haut, plus le modèle risque de rater la bonne direction d'apprentissage. D'autres hyperparamètres concernent généralement la taille des réseaux neuronaux qui composent l'architecture. 

On retrouve en traitement automatique des langues quelques modules d'architecture très communs que l'on se propose d'expliquer, en partie, ici.

\subsection{Embeddings}
\label{deep-learning:embeddings}

Représentation symbolique
\subsection{Linear (et CRF)}

\subsection{LSTM}

\subsection{CNN}